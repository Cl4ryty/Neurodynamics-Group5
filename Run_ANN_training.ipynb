{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Run_ANN_training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N9MNvXmVr5Ov",
        "H21PKA20sA4k",
        "nc6157tX6lF7",
        "aaXBjTIFsIMx",
        "umXRlplPsU60"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Cl4ryty/Neurodynamics-Group5/blob/main/Run_ANN_training.ipynb)"
      ],
      "metadata": {
        "id": "Rkbdb6veI1l4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **How to use**\n",
        "\n",
        "What this notebook does / includes:\n",
        "- connects to GoogleDrive and creates a directory to store the results in\n",
        "- contains the implementation of different DEs\n",
        "- creates an ANN and runs the training for each DE\n",
        "- plots the collected data and stores the data, plots, and trained ANNs\n",
        "\n",
        "Structure of the saved results:\n",
        "- running the training block generates a timestamped folder within the data directory of the selected path/directory containing \n",
        "  - `hyperparameters.txt`: the hyperparamete values used for this training run\n",
        "  - `system_info.txt`: a file conatining information about the system the training was run on – only when the training was done with the jupyter notebook\n",
        "  - `run_metrics.npy`: serialized numpy array of all the metrics collected for all subruns \n",
        "  - `plots/`: folder containing plots of the time metrics calculated over all subruns\n",
        "- if training for multiple subruns (setting `num_runs`>1 to run the training multiple times with the same parameters to calculate the time metrics), this folder will contain subfolders for each run, with the number of the run as names\n",
        "- the folders for individual runs (or the timestamped folder if `num_runs` is 1) contain:\n",
        "    - the saved trained ANNs as folders named after the DEs they were trained to solve\n",
        "    - `plots/`: folder containig plots of the training loss, training error, and model solution vs. true solution for all ANNs/DEs\n",
        "    - `activations.txt`: the activation functions used in the ANNs\n",
        "    - `metrics.txt`: metrics for all DEs to be used for later analysis\n",
        "    - `serialized_custom_loss_functions.txt`: seriazed dictionary of the custom loss function used for trainine each ANN with the DE names as keys – needed for loading the saved ANNs\n",
        "\n",
        "**Before running**:\n",
        "- change the `drive_path` in the block below to the folder/path in your Drive you want the results to be stored in.\n",
        "\n",
        "- change the hyperparameters to your liking."
      ],
      "metadata": {
        "id": "FKMi1TCLsxLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Run the code block below to connect to Drive and change to a folder to store the results\n"
      ],
      "metadata": {
        "id": "Pl2t1b12s1MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_path = \"RepoTest\" # change this to the folder/path you want"
      ],
      "metadata": {
        "id": "gyGF8EH4tRvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "os.makedirs('/content/gdrive/MyDrive/'+drive_path, exist_ok=True)\n",
        "\n",
        "os.chdir('/content/gdrive/MyDrive/'+drive_path)"
      ],
      "metadata": {
        "id": "6Ung5lv8swzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installation of needed libraries**"
      ],
      "metadata": {
        "id": "N9MNvXmVr5Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt -qq install lshw  # needed to get some system information"
      ],
      "metadata": {
        "id": "PfbmftpGr3s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "H21PKA20sA4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import dill as pickle\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "3qpJRs26r43Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Settings for prettier plots**"
      ],
      "metadata": {
        "id": "nc6157tX6lF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(font='Franklin Gothic Book',\n",
        "        rc={\n",
        "            'axes.axisbelow': False,\n",
        "            'axes.edgecolor': 'lightgrey',\n",
        "            'axes.facecolor': 'None',\n",
        "            'axes.grid': False,\n",
        "            'axes.labelcolor': 'dimgrey',\n",
        "            'axes.spines.right': False,\n",
        "            'axes.spines.top': False,\n",
        "            'figure.facecolor': 'white',\n",
        "            'lines.solid_capstyle': 'round',\n",
        "            'patch.edgecolor': 'w',\n",
        "            'patch.force_edgecolor': True,\n",
        "            'text.color': 'dimgrey',\n",
        "            'xtick.bottom': False,\n",
        "            'xtick.color': 'dimgrey',\n",
        "            'xtick.direction': 'out',\n",
        "            'xtick.top': False,\n",
        "            'ytick.color': 'dimgrey',\n",
        "            'ytick.direction': 'out',\n",
        "            'ytick.left': False,\n",
        "            'ytick.right': False,\n",
        "            'figure.autolayout': True})\n",
        "\n",
        "sns.set_context(\"notebook\", rc={\"font.size\": 16,\n",
        "                                \"axes.titlesize\": 20,\n",
        "                                \"axes.labelsize\": 16})\n",
        "\n",
        "\n",
        "# for prettier plots\n",
        "CB91_Blue = '#2CBDFE'\n",
        "CB91_Green = '#47DBCD'\n",
        "CB91_Pink = '#F3A0F2'\n",
        "CB91_Purple = '#9D2EC5'\n",
        "CB91_Violet = '#661D98'\n",
        "CB91_Amber = '#F5B14C'\n",
        "color_list = [CB91_Blue, CB91_Pink, CB91_Green, CB91_Amber,\n",
        "              CB91_Purple, CB91_Violet]\n",
        "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_list)\n"
      ],
      "metadata": {
        "id": "DBVFvy6i6jmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DE class and training_step function"
      ],
      "metadata": {
        "id": "aaXBjTIFsIMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(model, input, loss_function, optimizer):\n",
        "    \"\"\"\n",
        "    Performs a training step of the model using the given input,\n",
        "    calculating the loss with the given function and then using the optimizer to optimize the model.\n",
        "\n",
        "    :param tf.keras.Model model: the model to be trained\n",
        "    :param tf.Tensor input: the input\n",
        "    :param tf.keras.losses.Loss loss_function: the loss function\n",
        "    :param tf.keras.optimizers.Optimizer optimizer: the optimizer\n",
        "    :return: loss - the loss for this training step\n",
        "    :rtype: tf.Tensor\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        f = model(input)\n",
        "        loss = loss_function(input, f)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "# class for simple DE implementation\n",
        "# due to using the model in the loss function (which is necessary to be able to solve the DE) this class needs to be\n",
        "#   defined in the same scope (e.g. script) the training takes place and the model needs to be referenced with the\n",
        "#   variable name \"model\"\n",
        "class DE:\n",
        "    def __init__(self, name, input_min, input_max, eq, order, ic_x, ic_y, solution):\n",
        "        \"\"\"\n",
        "        Creates an object containing all necessary information for solving a DE with a NN and evaluating the solution.\n",
        "\n",
        "        :param str name: The name of the equation.\n",
        "        :param float input_min: The lower bound (inclusive) of the input range the DE is to be solved in.\n",
        "        :param float input_max: The upper bound (inclusive) of the input range the DE is to be solved in.\n",
        "        :param eq: lambda function specifying the differential equation with parameters\n",
        "            df_dx, (df_dxx, df_dxxx, df_dxxxx), f, x – \"lambda df_dx, df_dxx, f, x: …\" – with df_dx being the first derivative,\n",
        "            df_dxx the second derivative, f the function to be found, x the input.\n",
        "            The lambda parameters should always be the derivatives in ascending order (1st to nth), the function,\n",
        "            and the input, and the number of derivatives included should be equal to the order of the DE,\n",
        "            even if the DE itself does not contain all of them.\n",
        "        :param int order: the order of the equation (i.e. the highest order of derivative it contains),\n",
        "            e.g. 2 for a second order DE. Currently, supports only equations of order 1 - 4\n",
        "        :param list[float] ic_x: list of x values of the initial conditions,\n",
        "            e.g. for the initial conditions f(x=0)=1 and f(2)=3 this is [0., 2.]\n",
        "        :param list[float] ic_y: list of y values of the initial conditions,\n",
        "            e.g. for the initial conditions f(x=0)=1 and f(2)=3 this is [1., 3.]\n",
        "        :param solution: lambda function of the solution, containing one parameter x, i.e. \"lambda x: …\"\n",
        "        \"\"\"\n",
        "        # raise error if order is out of currently supported range\n",
        "        if order < 0 or order > 4:\n",
        "            raise ValueError(\"Only equations of order 1 - 4 are supported\")\n",
        "\n",
        "        self.name = name\n",
        "        self.input_min = input_min\n",
        "        self.input_max = input_max\n",
        "        self.eq = eq\n",
        "        self.order = order\n",
        "        self.ic_x = ic_x\n",
        "        self.ic_y = ic_y\n",
        "        self.solution = solution\n",
        "        self.loss_func = None\n",
        "\n",
        "    def get_inputs(self, number_points):\n",
        "        \"\"\"\n",
        "        Returns a tensor of shape (number_points, 1) with number_points evenly spaced values covering the input range of the\n",
        "        DE.\n",
        "\n",
        "        :param int number_points: The number of points in the input space to be returned.\n",
        "        :return: number_points evenly spaced values covering the input range of the DE.\n",
        "        :rtype: tf.Tensor\n",
        "        \"\"\"\n",
        "        inputs = tf.linspace(self.input_min, self.input_max, num=number_points)\n",
        "        inputs = tf.expand_dims(inputs, -1)\n",
        "        return inputs\n",
        "\n",
        "    def analytical_solution(self, x):\n",
        "        \"\"\"\n",
        "        Returns the solution for the given values using the DEs solution if it was provided.\n",
        "\n",
        "        :param tf.Tensor x: The values for which the solution should be computed.\n",
        "        :return: The solution for the provided x values if a solution function was provided duing DE initialization.\n",
        "        :rtype: tf.Tensor\n",
        "        \"\"\"\n",
        "        if self.solution is not None:\n",
        "            return self.solution(x)\n",
        "\n",
        "    def get_loss_function(self):\n",
        "        \"\"\"\n",
        "        Returns the loss function for the DE. The loss function is decorated with tf.function and complies with the\n",
        "         standard signature tensorflow expects for loss functions, so it takes the parameters y_true and y_pred.\n",
        "         However, only y_true is used and is expected to be the input x for which the NN should approximate the\n",
        "         solution to the DE.\n",
        "        :return: The loss function for the DE\n",
        "        \"\"\"\n",
        "        if self.loss_func is None:\n",
        "            self.loss_func = self.__make_ann_loss_func()\n",
        "        return self.__make_ann_loss_func()\n",
        "\n",
        "    def __make_ann_loss_func(self):\n",
        "\n",
        "        @tf.function\n",
        "        def ann_loss_function(y_true, y_pred):\n",
        "            \"\"\"\n",
        "            Loss function for solving a DE with an ANN. Only the parameter y_true is used and is expected to be the\n",
        "            input values – x – for which the ANN should approximate the solution to the DE.\n",
        "\n",
        "            :param y_true: The input values for which the ANN should approximate the DE's solution.\n",
        "            :param y_pred: Not used.\n",
        "            :return: The calculated loss.\n",
        "            \"\"\"\n",
        "            x = y_true\n",
        "\n",
        "            # gradient tapes for calculating the derivatives\n",
        "            with tf.GradientTape() as tape4:\n",
        "                with tf.GradientTape() as tape3:\n",
        "                    with tf.GradientTape() as tape2:\n",
        "                        with tf.GradientTape() as tape1:\n",
        "                            # need to explicitly watch x to be able to calculate gradients/derivatives afterwards\n",
        "                            tape1.watch(x)\n",
        "                            tape2.watch(x)\n",
        "                            tape3.watch(x)\n",
        "                            tape4.watch(x)\n",
        "                            # get the output of the ANN\n",
        "                            # -> assumes that the ANN can be referenced via the variable name \"model\"\n",
        "                            f = model(x)\n",
        "\n",
        "                            # calculate the derivatives and put the values in the DE\n",
        "                            df_dx = tape1.gradient(f, x)\n",
        "                            if self.order == 1:\n",
        "                                eq = self.eq(df_dx, f, x)\n",
        "                            if self.order > 1:\n",
        "                                df_dxx = tape2.gradient(df_dx, x)\n",
        "                                if self.order == 2:\n",
        "                                    eq = self.eq(df_dx, df_dxx, f, x)\n",
        "                            if self.order > 2:\n",
        "                                df_dxxx = tape3.gradient(df_dxx, x)\n",
        "                                if self.order == 3:\n",
        "                                    eq = self.eq(df_dx, df_dxx, df_dxxx, f, x)\n",
        "                            if self.order > 3:\n",
        "                                df_dxxxx = tape4.gradient(df_dxxx, x)\n",
        "                                if self.order == 4:\n",
        "                                    eq = self.eq(df_dx, df_dxx, df_dxxx, df_dxxxx, f, x)\n",
        "                # get the initial conditions\n",
        "                ic = 0.0\n",
        "                for ic_x, ic_y in zip(self.ic_x, self.ic_y):\n",
        "                    ic += tf.square(model(tf.constant(ic_x, shape=(1, 1))) - ic_y)\n",
        "            # the loss consists of the equation and initial conditions\n",
        "            return tf.math.reduce_mean(tf.square(eq)) + ic\n",
        "\n",
        "        return ann_loss_function"
      ],
      "metadata": {
        "id": "cVWWMvLysFs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing the DEs**"
      ],
      "metadata": {
        "id": "umXRlplPsU60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the DEs and storing them in a list\n",
        "equations = []\n",
        "\n",
        "\n",
        "# ########################   linear DEs   #####################\n",
        "# # ---------------------   first order   ---------------------\n",
        "test_de = DE(name=\"test_de\", input_min=-2., input_max=2., eq=lambda df_dx, f, x: df_dx + 2. * x * f, order=1, ic_x=[0],\n",
        "             ic_y=[1], solution=lambda x: tf.exp(-x ** 2))\n",
        "equations.append(test_de)\n",
        "\n",
        "\n",
        "a = 1.\n",
        "b = 1.\n",
        "gompertz = DE(name=\"gompertz\", input_min=-2., input_max=2.,\n",
        "              eq=lambda df_dx, f, x: f * (a - b * tf.math.log(f)),\n",
        "              order=1, ic_x=[0.], ic_y=[np.e],\n",
        "              solution=lambda x: tf.exp(1.))\n",
        "equations.append(gompertz)\n",
        "\n",
        "# Kirchhoff's law\n",
        "L = 4\n",
        "R = 12\n",
        "E_t = 60\n",
        "kirchhoff = DE(name=\"kirchhoff\", input_min=-0.5, input_max=0.5,\n",
        "               eq=lambda dI_dt, I, t: L * dI_dt + R * I - E_t,\n",
        "               order=1, ic_x=[1.], ic_y=[4.75],\n",
        "               solution=lambda x: 5 * (1 - tf.exp(-3 * x)))\n",
        "equations.append(kirchhoff)\n",
        "\n",
        "# Newtons first Law of cooling\n",
        "k = 0.092\n",
        "M = 25\n",
        "C = 4.36\n",
        "newtons_first = DE(name=\"newtons_first\", input_min=-2., input_max=2.,\n",
        "                   eq=lambda dT, T, x: dT - k * M + k * T,\n",
        "                   order=1, ic_x=[0.], ic_y=[24.98722161],\n",
        "                   solution=lambda x: M - (tf.exp(-C) * tf.exp(-k * x)))\n",
        "equations.append(newtons_first)\n",
        "\n",
        "# # ---------------------   second order   ----------------------------\n",
        "\n",
        "# Simple Harmonic Motion (of spring) / Newton's Second Law\n",
        "m = 1. / 16.\n",
        "k1 = 4.\n",
        "newtons_second_law = DE(name=\"newtons_second_law\", input_min=-2., input_max=2.,\n",
        "                        eq=lambda df_dx, df_dxx, f, x: m * df_dxx + k1 * f,\n",
        "                        order=2, ic_x=[1.], ic_y=[-0.278346201920130888224993],\n",
        "                        solution=lambda x: -2 * tf.sin(8 * x))\n",
        "equations.append(newtons_second_law)\n",
        "\n",
        "# x^2y′′+3xy′+4y=0\n",
        "c_1 = 5\n",
        "c_2 = 3\n",
        "second_order_euler = DE(name=\"second_order_euler\", input_min=2., input_max=6.,\n",
        "                        eq=lambda dy_dx, dy_dxx, y, x: tf.math.pow(x, 2) * dy_dxx + 3 * x * dy_dx + 4 * y,\n",
        "                        order=2, ic_x=[1, 2.476632271], ic_y=[5, 0.4037741136],\n",
        "                        solution=lambda x: c_1 * (1. / x) * tf.math.cos(tf.sqrt(3.) * tf.math.log(x)) + c_2 * (\n",
        "                                1. / x) * tf.math.sin(tf.sqrt(3.) * tf.math.log(x)))\n",
        "equations.append(second_order_euler)\n",
        "\n",
        "second_1 = DE(name=\"second_1\", input_min=-2., input_max=2.,\n",
        "              eq=lambda df_dx, df_dxx, f, x: 3 * ((x + 6.) ** 2.) * df_dxx + 25 * (x + 6.) * df_dx - 16 * f,\n",
        "              order=2, ic_x=[-5., -4.], ic_y=[2, 1.591307302],\n",
        "              solution=lambda x: tf.abs(x + 6.) ** (2. / 3.) + tf.abs(x + 6.) ** (-8.))\n",
        "equations.append(second_1)\n",
        "\n",
        "second_2 = DE(name=\"second_2\", input_min=-2., input_max=2.,\n",
        "              eq=lambda df_dx, df_dxx, x, t: df_dxx + x,\n",
        "              order=2, ic_x=[0, 0.6366197724], ic_y=[1, 1],\n",
        "              solution=lambda t: tf.cos(t) + tf.sin(t))\n",
        "equations.append(second_2)\n",
        "\n",
        "# 2t²y'' + 3ty' − y = 0\n",
        "new_2nd_linear_1 = DE(name=\"new_2nd_linear_1\", input_min=1., input_max=5.,\n",
        "                      eq=lambda df_dx, df_dxx, f, x: 2 * (x ** 2) * df_dxx + 3 * x * df_dx - f,\n",
        "                      order=2, ic_x=[4], ic_y=[2],\n",
        "                      solution=lambda x: x ** (1 / 2))\n",
        "equations.append(new_2nd_linear_1)\n",
        "\n",
        "# y'' + 3y' - 10y = 0\n",
        "new_2nd_linear_2 = DE(name=\"new_2nd_linear_2\", input_min=-2., input_max=2.,\n",
        "                      eq=lambda df_dx, df_dxx, f, x: df_dxx + 3 * df_dx - 10 * f,\n",
        "                      order=2, ic_x=[0.], ic_y=[1.],\n",
        "                      solution=lambda x: (8 / 7) * tf.exp(2 * x) + (-1 / 7) * tf.exp(-5 * x))\n",
        "equations.append(new_2nd_linear_2)\n",
        "\n",
        "# y″ + 5y′ + 4y = 0\n",
        "new_2nd_linear_3 = DE(name=\"new_2nd_linear_3\", input_min=-2., input_max=2.,\n",
        "                      eq=lambda df_dx, df_dxx, f, x: df_dx + 5 * df_dx + 4 * f,\n",
        "                      order=2, ic_x=[0.], ic_y=[1.],\n",
        "                      solution=lambda x: -1 * tf.exp(-x) + 2 * tf.exp(-4 * x))\n",
        "equations.append(new_2nd_linear_3)\n",
        "\n",
        "# # ------------------   third order ---------------------------\n",
        "\n",
        "# third_order, y''' - 9y'' + 15y' + 25y = 0\n",
        "third_order = DE(name=\"third_order\", input_min=0., input_max=1.,\n",
        "                 eq=lambda dy_dt, dy_dtt, dy_dttt, y, x: dy_dttt - 9 * dy_dtt + 15 * dy_dt + 25 * y,\n",
        "                 order=3, ic_x=[0, 1, -1], ic_y=[3, 297.1941976, 2.718281828],\n",
        "                 solution=lambda x: tf.math.exp(-x) + tf.math.exp(5 * x) + x * tf.math.exp(5 * x))\n",
        "equations.append(third_order)\n",
        "\n",
        "# third_order_2, y'''+y''-2y=e^x(14+34x+15x^2)\n",
        "third_order_2 = DE(name=\"third_order_2\", input_min=0., input_max=1.,\n",
        "                   eq=lambda dy_dt, dy_dtt, dy_dttt, y, x: dy_dttt + dy_dtt - 2 * y - tf.math.exp(\n",
        "                       14 + 34 * x + 15 * tf.math.pow(x, 2)),\n",
        "                   order=3, ic_x=[0, 1.570796327, 1], ic_y=[2, 35.53210822, 8.529089278],\n",
        "                   solution=lambda x: tf.math.exp(x) + tf.math.exp((-x)) * (\n",
        "                           tf.math.cos(x) + tf.math.sin(x)) + tf.math.exp(x) * (\n",
        "                                              tf.math.pow(x, 2) + tf.math.pow(x, 3)))\n",
        "equations.append(third_order_2)\n",
        "\n",
        "# third_order_3 y''' + y'' - 6y' + 4y = 0\n",
        "third_order_3 = DE(name=\"third_order_3\", input_min=0., input_max=1.,\n",
        "                   eq=lambda dy_dt, dy_dtt, dy_dttt, y, x: dy_dttt + dy_dtt - 6 * dy_dt + 4 * y,\n",
        "                   order=3, ic_x=[0, 1, 2], ic_y=[3, 6.199652613, 19.23832807],\n",
        "                   solution=lambda x: tf.math.exp(x) + tf.math.exp((1.236067977) * x) + tf.math.exp((-3.236067977) * x))\n",
        "equations.append(third_order_3)\n",
        "\n",
        "# ###########################   nonlinear   #################################\n",
        "# # ------------------------   first order   ---------------------------------\n",
        "\n",
        "k2 = 0.07\n",
        "L2 = 900\n",
        "logistic_equation = DE(name=\"logistic_equation\", input_min=-2., input_max=2.,\n",
        "                       eq=lambda df_dx, f, x: df_dx - k2 * f * (1 - f / L2),\n",
        "                       order=1, ic_x=[0], ic_y=[50],\n",
        "                       solution=lambda x: 900 / (17 * tf.exp(-0.07 * x)))\n",
        "equations.append(logistic_equation)\n",
        "\n",
        "# nonlinear y' = x(y^3) where y(0)=2\n",
        "nonlinear = DE(name=\"nonlinear\", input_min=-2., input_max=2.,\n",
        "               eq=lambda df_dx, y, x: df_dx - x * tf.math.pow(y, 3),\n",
        "               order=1, ic_x=[0], ic_y=[2],\n",
        "               solution=lambda x: tf.math.pow((1 / 4 - tf.math.pow(x, 2)), -0.5))\n",
        "equations.append(nonlinear)\n",
        "\n",
        "# # ------------------------   second order   ------------------------------------\n",
        "\n",
        "# Painlevé II transcendent: w'' = 2w^3 + zw + α\n",
        "alpha = 3.\n",
        "painleve_2_transcendent = DE(name=\"painleve_2_transcendent\", input_min=-2., input_max=2.,\n",
        "                             eq=lambda df_dx, df_dxx, y, x: 2 * (y ** 3) + x * y + alpha,\n",
        "                             order=2, ic_x=[4.7], ic_y=[0],\n",
        "                             solution=lambda x: None)\n",
        "equations.append(painleve_2_transcendent)\n",
        "\n",
        "second_order_nonlinear = DE(name=\"second_order_nonlinear\", input_min=-2., input_max=2.,\n",
        "                            eq=lambda df_dx, df_dxx, f, x: -2. * x * (df_dx ** 2),\n",
        "                            order=2, ic_x=[0], ic_y=[2],\n",
        "                            solution=lambda x: 0.5 * (tf.math.log(tf.abs(x - 1.)) - tf.math.log(tf.abs(x + 1.))) + 2.)\n",
        "equations.append(second_order_nonlinear)\n",
        "\n",
        "mu = 1.\n",
        "van_der_pol = DE(name=\"van_der_pol\", input_min=0., input_max=2,\n",
        "                 eq=lambda dfdt, dfdtt, x, t: dfdtt - mu * (1 - x ** 2) * dfdt + x,\n",
        "                 order=2, ic_x=[0], ic_y=[2.],\n",
        "                 solution=lambda x: None)\n",
        "equations.append(van_der_pol)\n",
        "\n",
        "# y'' + 3y²y' = 0 for y(1) = 2 , y'(1) = 1\n",
        "new_2nd_nonlinear_1 = DE(name=\"new_2nd_nonlinear_1\", input_min=0., input_max=2,\n",
        "                         eq=lambda dfdt, dfdtt, f, t: dfdtt + 3 * (f ** 2) * dfdt,\n",
        "                         order=2, ic_x=[1.], ic_y=[2.],\n",
        "                         solution=lambda x: x + 1)\n",
        "equations.append(new_2nd_nonlinear_1)\n",
        "\n",
        "# y''/y'² + y'(e^y) = 0 for y(0) = 0, y'(0) = 1\n",
        "new_2nd_nonlinear_2 = DE(name=\"new_2nd_nonlinear_2\", input_min=0., input_max=2,\n",
        "                         eq=lambda dfdt, dfdtt, f, t: (dfdtt / (dfdt ** 2)) + dfdt * tf.exp(f),\n",
        "                         order=2, ic_x=[0.], ic_y=[0.],\n",
        "                         solution=lambda x: tf.math.log(x + 1))\n",
        "equations.append(new_2nd_nonlinear_2)\n",
        "\n",
        "# # ------------------------   third order   -----------------------------------\n",
        "\n",
        "# third_order_nonlin, y′′′+(y′)^2−yy′′=0\n",
        "third_order_nonlin = DE(name=\"third_order_nonlin\", input_min=0., input_max=1.,\n",
        "                        eq=lambda dy_dt, dy_dtt, dy_dttt, y, x: dy_dttt + tf.math.pow(dy_dt, 2) - y * dy_dtt,\n",
        "                        order=3, ic_x=[0, 1, 2], ic_y=[1, 2.08616127, 6.524391382],\n",
        "                        solution=lambda x: tf.math.exp(x) + tf.math.exp(-x) - 1)\n",
        "equations.append(third_order_nonlin)\n",
        "\n",
        "# third_order_v2, x^3(u''') - 3x^2(u'') + 7x(u') - 8u = f, while f = x^2/(1+ (ln|x|)^2), and f(0) = 0\n",
        "A = 2\n",
        "B = 2\n",
        "C1 = 2\n",
        "third_order_v2 = DE(name=\"third_order_v2\", input_min=0., input_max=1.,\n",
        "                    eq=lambda du_dx, du_dxx, du_dxxx, u, x: tf.math.pow(x, 3) * du_dxxx - 3 * (\n",
        "                            x ** 2) * du_dxx + 7 * du_dx - 8 * u,\n",
        "                    order=3, ic_x=[0, 1, 3], ic_y=[0, 2, 26.188934797822288],\n",
        "                    solution=lambda x: (\n",
        "                            A + B * tf.math.log(x) + C1 * (tf.math.log(x) ** 2) * (x ** 2) - ((x ** 2) / 2) * (\n",
        "                            (1 - (tf.math.log(x)) ** 2) * tf.math.atan(tf.math.log(x)) + tf.math.log(\n",
        "                        x) * tf.math.log((1 + (tf.math.log(x)) ** 2) - (tf.math.log(x))))))\n",
        "equations.append(third_order_v2)"
      ],
      "metadata": {
        "id": "5_19-lRwsS9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameters**"
      ],
      "metadata": {
        "id": "ZWGIeabXt2UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the hyperparameters\n",
        "epochs = 200  # number of epochs for each run\n",
        "learning_rate = 0.01\n",
        "loss_threshold = 0.00001  # threshold for which time and epochs until the loss is lower than this is recorded\n",
        "num_runs = 2  # number of consecutive runs to calculate metrics over time measurements\n",
        "input_size = 400  # number of input values over which the ANN approximates the solution of the DEs\n",
        "seed = 42  # seed for initializing the ANN weights and biases to keep the results the same for all runs"
      ],
      "metadata": {
        "id": "3u4I0Qwrtxk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "qUmHoTHSsZH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wht2sNgQrtVv"
      },
      "outputs": [],
      "source": [
        "# define path where output files will be stored\n",
        "top_path = os.path.abspath(os.path.join(os.getcwd(), 'data', str(time.time())))\n",
        "os.makedirs(top_path)\n",
        "\n",
        "# save some information about the current system this is running on\n",
        "!(uname -a; sudo lshw; nvidia-smi) >  data/$(ls -t ./data | head -1)/system_info.txt\n",
        "\n",
        "# save the hyperparameters\n",
        "hyperparameters = [(\"epochs\", epochs), (\"learning_rate\", learning_rate), (\"loss_threshold\", loss_threshold),\n",
        "                   (\"num_runs\", num_runs), (\"input_size\", input_size), (\"seed\", seed)]\n",
        "hyperparameters = np.array(hyperparameters)\n",
        "np.savetxt(os.path.join(top_path, \"hyperparameters.txt\"), hyperparameters, fmt=\"%s\", delimiter=\",\")\n",
        "\n",
        "\n",
        "list_of_run_metrics = []\n",
        "\n",
        "if num_runs <= 1:\n",
        "    # assume that one run should be executed\n",
        "    num_runs = 1\n",
        "    # use the already created directory\n",
        "    path_wd = top_path\n",
        "    \n",
        "\n",
        "for run_num in range(num_runs):\n",
        "    if num_runs  > 1:\n",
        "        # create subdirectory for each run\n",
        "        path_wd = os.path.abspath(os.path.join(top_path, str(run_num)))\n",
        "        os.makedirs(path_wd)\n",
        "        print(\"____________________ starting run \", run_num, \"____________________________\")\n",
        "\n",
        "    # lists for storing results\n",
        "    final_losses = []\n",
        "    final_errors = []\n",
        "    de_names = []\n",
        "\n",
        "    first_epoch_under_threshold = []\n",
        "    time_to_threshold = []\n",
        "    total_training_time = []\n",
        "\n",
        "    functions_dict = {}\n",
        "\n",
        "    # create directory for the plots\n",
        "    try:\n",
        "        os.makedirs(os.path.join(path_wd, \"plots\"))\n",
        "    except FileExistsError:\n",
        "        # directory already exists\n",
        "        pass\n",
        "\n",
        "    # create directory for the losses\n",
        "    try:\n",
        "        os.makedirs(os.path.join(path_wd, \"train_losses\"))\n",
        "    except FileExistsError:\n",
        "        # directory already exists\n",
        "        pass\n",
        "\n",
        "    # create directory for the errors\n",
        "    try:\n",
        "        os.makedirs(os.path.join(path_wd, \"train_errors\"))\n",
        "    except FileExistsError:\n",
        "        # directory already exists\n",
        "        pass\n",
        "\n",
        "    # create RMSE function object for later use\n",
        "    rmse = tf.keras.metrics.RootMeanSquaredError()\n",
        "\n",
        "    # run the training and conversion for all DEs\n",
        "    for i, de in enumerate(equations):\n",
        "        print(\"\\n\\nWorking on \" + de.name + \", equation\", i, \"of\", len(equations) - 1)\n",
        "        # save the loss function in the dict\n",
        "        functions_dict[de.name] = de.get_loss_function()\n",
        "\n",
        "        # get the loss function and inputs from the DE object\n",
        "        loss_function = de.get_loss_function()\n",
        "        x = de.get_inputs(input_size)\n",
        "\n",
        "        # Save dataset so SNN toolbox can find it.\n",
        "        np.savez_compressed(os.path.join(path_wd, 'x_test'), x)\n",
        "        np.savez_compressed(os.path.join(path_wd, 'y_test'), x)\n",
        "\n",
        "        # initialize the model and optimizer\n",
        "        ns = 10\n",
        "        model = tf.keras.Sequential([tf.keras.layers.Dense(units=ns, activation=tf.nn.silu,\n",
        "                                                           kernel_initializer=tf.random_normal_initializer(seed=seed),\n",
        "                                                           bias_initializer=tf.random_normal_initializer(seed=seed),\n",
        "                                                           name=\"first\",\n",
        "                                                           input_shape=(1,)),\n",
        "                                     tf.keras.layers.Dense(units=ns, activation=tf.nn.sigmoid,\n",
        "                                                           kernel_initializer=tf.random_normal_initializer(seed=seed),\n",
        "                                                           bias_initializer=tf.random_normal_initializer(seed=seed),\n",
        "                                                           name=\"second\"),\n",
        "                                     tf.keras.layers.Dense(units=ns, activation=tf.nn.sigmoid,\n",
        "                                                           kernel_initializer=tf.random_normal_initializer(seed=seed),\n",
        "                                                           bias_initializer=tf.random_normal_initializer(seed=seed),\n",
        "                                                           name=\"third\"),\n",
        "                                     tf.keras.layers.Dense(units=1, activation=tf.nn.selu,\n",
        "                                                           kernel_initializer=tf.random_normal_initializer(seed=seed),\n",
        "                                                           bias_initializer=tf.random_normal_initializer(seed=seed),\n",
        "                                                           name=\"fourth\")\n",
        "\n",
        "                                     ])\n",
        "\n",
        "        # store the model's activation functions for easier replication\n",
        "        with open(os.path.join(path_wd, 'activations.txt'), 'w') as f:\n",
        "            for layer in model.layers:\n",
        "                try:\n",
        "                    print(layer.activation, file=f)\n",
        "                except:  # some layers don't have any activation\n",
        "                    pass\n",
        "\n",
        "        # initialize the optimizer, compile the model and print a summary\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "        model.compile(optimizer, test_de.get_loss_function())\n",
        "        print(model.summary())\n",
        "\n",
        "        # Initialize lists for later visualization.\n",
        "        train_losses = []\n",
        "        train_errors = []\n",
        "\n",
        "        under_threshold = False\n",
        "\n",
        "        # get the start time for recording time metrics\n",
        "        start_time = time.process_time()\n",
        "\n",
        "        # We train for epochs.\n",
        "        for epoch in range(epochs):\n",
        "            # print the current loss every 100 epochs to check if training is working\n",
        "            if epoch % 100 == 0:\n",
        "                f = model(x)\n",
        "                print(f'Epoch: {str(epoch)} starting with loss {loss_function(x, f)}')\n",
        "\n",
        "            # run training and store the loss\n",
        "            train_loss = training_step(model, x, loss_function, optimizer)\n",
        "            train_losses.append(tf.squeeze(train_loss))\n",
        "\n",
        "            # calculate error and store it\n",
        "            # only possible if solution is not None\n",
        "            try:\n",
        "                approx = tf.squeeze(model(x))\n",
        "                solution = tf.squeeze(de.analytical_solution(tf.squeeze(x)))\n",
        "                error = rmse(approx, solution).numpy()\n",
        "                train_errors.append(error)\n",
        "            except ValueError:\n",
        "                # solution is None, do nothing\n",
        "                pass\n",
        "\n",
        "            # check if loss is under threshold\n",
        "            if tf.squeeze(train_loss) < loss_threshold and not under_threshold:\n",
        "                time_to_threshold.append(time.process_time() - start_time)\n",
        "                first_epoch_under_threshold.append(epoch)\n",
        "                under_threshold = True\n",
        "\n",
        "        # store total runtime and time to threshold\n",
        "        # use None if it was not reached to have equal sized lists for all DEs\n",
        "        total_training_time.append(time.process_time() - start_time)\n",
        "        if not under_threshold:\n",
        "            time_to_threshold.append(None)\n",
        "            first_epoch_under_threshold.append(None)\n",
        "\n",
        "        # save final loss, final error (if it exists), and de name\n",
        "        if train_errors:\n",
        "            final_errors.append(train_errors[-1])\n",
        "        else:\n",
        "            # no train errors due to missing solution, store None instead\n",
        "            final_errors.append(None)\n",
        "        final_losses.append(train_losses[-1])\n",
        "        de_names.append(de.name)\n",
        "\n",
        "        # save the model\n",
        "        model_name = de.name\n",
        "        model.save(os.path.join(path_wd, model_name))\n",
        "\n",
        "        # save train loss and train error to file for later evaulation\n",
        "        np.savetxt(os.path.join(path_wd, \"train_losses\", model_name + \"-train_losses.txt\"), np.array(train_losses),\n",
        "                   fmt=\"%s\", delimiter=\",\")\n",
        "        np.savetxt(os.path.join(path_wd, \"train_errors\", model_name + \"-train_errors.txt\"), np.array(train_errors),\n",
        "                   fmt=\"%s\", delimiter=\",\")\n",
        "\n",
        "        # plot training losses and errors\n",
        "        plt.figure()\n",
        "        plt.plot(train_losses)\n",
        "        plt.xlabel(\"Training steps\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(de.name)\n",
        "        figname = de.name + \"__loss.png\"\n",
        "        plt.savefig(os.path.join(path_wd, \"plots\", figname))\n",
        "        plt.show(block=False)\n",
        "        plt.pause(0.001)\n",
        "\n",
        "        if train_errors:\n",
        "            plt.figure()\n",
        "            plt.plot(train_errors)\n",
        "            plt.xlabel(\"Training steps\")\n",
        "            plt.ylabel(\"RMSE\")\n",
        "            plt.title(de.name)\n",
        "            figname = de.name + \"__error.png\"\n",
        "            plt.savefig(os.path.join(path_wd, \"plots\", figname))\n",
        "            plt.show(block=False)\n",
        "            plt.pause(0.001)\n",
        "\n",
        "        # plot the model's approximation and the actual solution\n",
        "        approx = model(x)\n",
        "        plt.plot(tf.squeeze(x), tf.squeeze(approx), label=\"model's solution\")\n",
        "        try:\n",
        "            plt.plot(tf.squeeze(x), tf.squeeze(de.analytical_solution(tf.squeeze(x))), label=\"true solution\",\n",
        "                     linestyle=\"dashed\")\n",
        "        except ValueError:\n",
        "            # no solution, do nothing -> only plot model's approximation\n",
        "            pass\n",
        "        plt.legend()\n",
        "        plt.title(de.name)\n",
        "\n",
        "        figname = de.name + \"__solution.png\"\n",
        "        plt.savefig(os.path.join(path_wd, \"plots\", figname))\n",
        "        plt.show(block=False)\n",
        "        plt.pause(0.001)\n",
        "\n",
        "        # store the dictionary with the loss functions\n",
        "        dict_file_name = 'serialized_custom_loss_functions.txt'\n",
        "        f = open(os.path.join(path_wd, dict_file_name), 'wb')  # opened the file in write and binary mode\n",
        "        pickle.dump(functions_dict, f)  # dumping the content into the file\n",
        "        f.close()  # closing the file\n",
        "\n",
        "    # create an array with all final losses + errors and de names\n",
        "    final_losses = np.array(final_losses)\n",
        "    final_errors = np.array(final_errors)\n",
        "    de_names = np.array(de_names)\n",
        "    time_to_threshold = np.array(time_to_threshold)\n",
        "    total_training_time = np.array(total_training_time)\n",
        "    first_epoch_under_threshold = np.array(first_epoch_under_threshold)\n",
        "\n",
        "    metrics = np.array(\n",
        "        [de_names, final_losses, final_errors, first_epoch_under_threshold, time_to_threshold, total_training_time]).T\n",
        "\n",
        "    list_of_run_metrics.append(metrics)\n",
        "\n",
        "    # save metrics as file\n",
        "    np.savetxt(os.path.join(path_wd, \"metrics.txt\"), metrics, fmt=\"%s\", delimiter=\",\",\n",
        "               header=\"de_names,final_losses,final_errors,first_epoch_under_threshold,time_to_threshold,\"\n",
        "                      \"total_training_time\")\n",
        "\n",
        "\n",
        "\n",
        "if num_runs > 1:\n",
        "    # ------------------------------------------------------------------------------\n",
        "    # calculate time metrics for all runs\n",
        "\n",
        "    # stack the metrics arrays of all runs\n",
        "    time_metrics = np.stack(list_of_run_metrics)\n",
        "\n",
        "    # save array for later use\n",
        "    np.save(os.path.join(top_path, \"run_metrics\"), time_metrics)\n",
        "\n",
        "    # get only the time metrics\n",
        "    time_metrics = np.array(time_metrics[:, :, -2:], dtype=float)\n",
        "\n",
        "    means = np.mean(time_metrics, axis=0)\n",
        "    medians = np.median(time_metrics, axis=0)\n",
        "    mins = np.min(time_metrics, axis=0)\n",
        "    maxs = np.max(time_metrics, axis=0)\n",
        "\n",
        "    # create directory for the plots\n",
        "    try:\n",
        "        os.makedirs(os.path.join(top_path, \"plots\"))\n",
        "    except FileExistsError:\n",
        "        # directory already exists\n",
        "        pass\n",
        "\n",
        "    # plots for total training times\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.boxplot(time_metrics[:, :, 1].T.tolist(), labels=de_names)\n",
        "    plt.ylabel(\"Total training time\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Total_training_times.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.bar(de_names, means[:, 1])\n",
        "    plt.ylabel(\"Mean total training time\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Mean_total_training_times.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.bar(de_names, medians[:, 1])\n",
        "    plt.ylabel(\"Median total training time\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Median_total_training_times.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.bar(de_names, mins[:, 1])\n",
        "    plt.ylabel(\"Min total training time\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Min_total_training_times.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.bar(de_names, maxs[:, 1])\n",
        "    plt.ylabel(\"Max total training time\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Max_total_training_times.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    # plots for times to loss under threshold\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.boxplot(time_metrics[:, :, 0].T.tolist(), labels=de_names)\n",
        "    plt.ylabel(\"Times to threshold\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Times_to_threshold.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.bar(de_names, means[:, 0])\n",
        "    plt.ylabel(\"Mean time to threshold\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Mean_time_to_threshold.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.bar(de_names, medians[:, 0])\n",
        "    plt.ylabel(\"Median time to threshold\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Median_time_to_threshold.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.bar(de_names, mins[:, 0])\n",
        "    plt.ylabel(\"Min time to threshold\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Min_time_to_threshold.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.bar(de_names, maxs[:, 0])\n",
        "    plt.ylabel(\"Max time to threshold\")\n",
        "    plt.xlabel(\"DEs\")\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    figname = \"Max_time_to_threshold.png\"\n",
        "    plt.savefig(os.path.join(top_path, \"plots\", figname))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(0.001)"
      ]
    }
  ]
}